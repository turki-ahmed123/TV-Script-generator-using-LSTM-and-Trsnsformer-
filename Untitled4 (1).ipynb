{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "oUGwsAc0rAWh",
        "outputId": "43198863-0201-4148-bb9a-c42a96c07771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 4000/4000\n",
            "Train loss: 0.1587 | Val loss: 0.1602\n",
            "Time: 53.1 min\n",
            "Model saved!\n",
            "\n",
            "============================================================\n",
            "GENERATED SIMPSONS SCRIPT\n",
            "============================================================\n",
            "Homer: If this is a test, I’m failing spectacularly. (deadpan)\n",
            "Lou: There’s no problem that can’t be made worse by my advice. (whispering)\n",
            "Reverend Lovejoy: That’s not a bug, it’s a feature! (laughing)\n",
            "Kent Brockman: You had one job, and somehow, you still outdid yourself. (sarcastically)\n",
            "Krusty: We’ve officially reached peak nonsense. (sighs)\n",
            "Cletus: This donut tastes like bad decisions. (sighs)\n",
            "Nelson: You can’t prove it was me… okay, maybe you can. (sarcastically)\n",
            "Gil: If this is a test, I’m failing spectacularly. (sarcastically)\n",
            "Grandpa: There’s no problem that can’t be made worse by my advice. (sarcastically)\n",
            "Hans Moleman: Sometimes silence is the only sane response. (sighs)\n",
            "Selma: You can’t prove it was me… okay, maybe you can. (shouting)\n",
            "Gil: Sometimes silence is the only sane response. (laughing)\n",
            "Patty: I could really use a nap right now. (deadpan)\n",
            "Gil: That’s not a bug, it’s a feature! (whispering)\n",
            "Nelson: I could really use a nap right now. (laughing)\n",
            "Cletus: Whoever said laughter \n"
          ]
        }
      ],
      "source": [
        "# CELL 1 — Install & Setup (run once)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 2>/dev/null || pip install torch\n",
        "\n",
        "# Upload your dataset (simpsons_style_50000.txt)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # ← Click here and upload your file\n",
        "\n",
        "# CELL 2 — FULL TRAINING + GENERATION (just run this)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Load the file you just uploaded\n",
        "filename = list(uploaded.keys())[0]\n",
        "with open(filename, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print(f\"Loaded {len(text):,} characters\")\n",
        "\n",
        "# Character-level vocab\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join(itos[i] for i in l)\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data, val_data = data[:n], data[n:]\n",
        "\n",
        "# Hyperparameters (optimized for Colab free GPU)\n",
        "batch_size = 128\n",
        "block_size = 256\n",
        "embed_dim = 256\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "dropout = 0.1\n",
        "max_iters = 4000      # ~25-35 min on T4\n",
        "eval_interval = 400\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "# Model (fixed + slightly bigger for better quality)\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(embed_dim, head_size, bias=False)\n",
        "        self.query = nn.Linear(embed_dim, head_size, bias=False)\n",
        "        self.value = nn.Linear(embed_dim, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.head_size = head_size # Store head_size as an instance variable\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        wei = q @ k.transpose(-2,-1) * (self.head_size ** -0.5) # Use self.head_size\n",
        "        wei = wei.masked_fill(torch.tril(torch.ones(T,T,device=device))==0, float('-inf'))\n",
        "        wei = torch.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        return wei @ v\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(num_heads * head_size, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        return self.dropout(self.proj(out))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 4*embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4*embed_dim, embed_dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        head_size = embed_dim // num_heads\n",
        "        self.sa = MultiHeadAttention(num_heads, head_size)\n",
        "        self.ffwd = FeedForward()\n",
        "        self.ln1 = nn.LayerNorm(embed_dim)\n",
        "        self.ln2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class SimpsonsGPT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.pos_emb = nn.Embedding(block_size, embed_dim)\n",
        "        self.blocks = nn.Sequential(*[Block() for _ in range(num_layers)])\n",
        "        self.ln_f = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        x = self.token_emb(idx) + self.pos_emb(torch.arange(T, device=device))\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            loss = nn.functional.cross_entropy(logits.view(-1, vocab_size), targets.view(-1))\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens, temperature=0.9, top_k=40):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            if top_k:\n",
        "                v, _ = torch.topk(logits, top_k)\n",
        "                logits[logits < v[:, [-1]]] = -float('inf')\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            next_idx = torch.multinomial(probs, 1)\n",
        "            idx = torch.cat((idx, next_idx), dim=1)\n",
        "        return idx\n",
        "\n",
        "# Training\n",
        "model = SimpsonsGPT().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-4, betas=(0.9, 0.95))\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(100)\n",
        "        for k in range(100):\n",
        "            xb, yb = get_batch(split)\n",
        "            _, loss = model(xb, yb)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean().item()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "print(\"Training started...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for step in range(max_iters + 1):\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        elapsed = (time.time() - start_time) / 60\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Step {step}/{max_iters}\")\n",
        "        print(f\"Train loss: {losses['train']:.4f} | Val loss: {losses['val']:.4f}\")\n",
        "        print(f\"Time: {elapsed:.1f} min\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), 'simpsons_gpt_colab.pth')\n",
        "print(\"Model saved!\")\n",
        "\n",
        "# Generate a sample\n",
        "model.eval()\n",
        "context = torch.tensor(encode(\"Homer:\"), dtype=torch.long, device=device).unsqueeze(0)\n",
        "generated = model.generate(context, max_new_tokens=1000, temperature=0.9, top_k=50)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERATED SIMPSONS SCRIPT\")\n",
        "print(\"=\"*60)\n",
        "print(decode(generated[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f6a6c7c"
      },
      "outputs": [],
      "source": [
        "# Install Gradio\n",
        "!pip install gradio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "51e97eca",
        "outputId": "e907c955-de51-460e-84c5-d298db0c1837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5254918e7fca75f02a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5254918e7fca75f02a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "# Ensure the model is in evaluation mode and on the correct device\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "def generate_simpsons_script_gradio(starting_scene, main_plot, tone, initial_text, max_new_tokens, temperature, top_k, character_to_count, count_dialogues_flag):\n",
        "    # Replicate prompt construction logic from the notebook\n",
        "    episode_title = f\"The One Where {main_plot.split()[0]} {' '.join(main_plot.split()[1:])}\" if not main_plot.startswith(\"Homer\") else main_plot.capitalize()\n",
        "    prompt = f\"Episode Title: {episode_title}\\n\\n{starting_scene}\\n\\n*FADE IN:*\\n{initial_text}\"\n",
        "\n",
        "    # Filter out characters from the prompt that are not in the vocabulary\n",
        "    filtered_prompt_chars = [c for c in prompt if c in stoi]\n",
        "    filtered_prompt = \"\".join(filtered_prompt_chars)\n",
        "\n",
        "    context = torch.tensor(encode(filtered_prompt), device=device).unsqueeze(0)\n",
        "\n",
        "    # Generate the script\n",
        "    full_drama_tokens = model.generate(\n",
        "        context,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=temperature,\n",
        "        top_k=top_k\n",
        "    )[0].tolist()\n",
        "\n",
        "    script = decode(full_drama_tokens)\n",
        "\n",
        "    # Clean up a bit for readability\n",
        "    script = script.replace(\"Homer:\", \"\\nHomer:\").replace(\"Marge:\", \"\\nMarge:\").replace(\"Bart:\", \"\\nBart:\").replace(\"Lisa:\", \"\\nLisa:\")\n",
        "    script = script.replace(\"Mr. Burns:\", \"\\nMr. Burns:\").replace(\"Smithers:\", \"\\nSmithers:\").replace(\"Chief Wiggum:\", \"\\nChief Wiggum:\")\n",
        "\n",
        "    dialogue_count_message = \"\"\n",
        "    if count_dialogues_flag and character_to_count:\n",
        "        # Count occurrences of the character's name followed by a colon and a newline\n",
        "        # We add a newline before the character name to avoid counting partial matches within dialogue.\n",
        "        dialogues = script.count(f\"\\n{character_to_count}:\")\n",
        "        dialogue_count_message = f\"\\n\\n--- Dialogue Count for {character_to_count}: {dialogues} ---\"\n",
        "\n",
        "    return script + dialogue_count_message\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_simpsons_script_gradio,\n",
        "    inputs=[\n",
        "        gr.Dropdown(\n",
        "            [\"Springfield Nuclear Plant - Day\", \"The Simpsons living room - Night\", \"Springfield Elementary\", \"Moe's Tavern\", \"Krusty the Clown Show set\", \"Springfield Town Hall\", \"The Android's Dungeon comic book store\", \"Kwik-E-Mart\", \"Springfield Retirement Castle\", \"Treehouse of Horror opening\"],\n",
        "            label=\"Starting Scene\",\n",
        "            value=\"Springfield Nuclear Plant - Day\"\n",
        "        ),\n",
        "        gr.Dropdown(\n",
        "            [\"Homer accidentally causes a meltdown\", \"Lisa discovers corruption in Springfield\", \"Bart becomes mayor for a day\", \"Marge runs for school board\", \"Mr. Burns tries to buy the town\", \"Apu faces deportation\", \"Krusty is cancelled\", \"Grandpa Simpson tells his war stories\", \"A new teacher changes everything\", \"Springfield bans something ridiculous\"],\n",
        "            label=\"Main Plot\",\n",
        "            value=\"Homer accidentally causes a meltdown\"\n",
        "        ),\n",
        "        gr.Dropdown(\n",
        "            [\"Dramatic with heart\", \"Dark comedy\", \"Pure chaos\", \"Emotional family drama\", \"Political satire\", \"Very silly\", \"Treehouse of Horror (horror)\"],\n",
        "            label=\"Tone\",\n",
        "            value=\"Dramatic with heart\"\n",
        "        ),\n",
        "        gr.Textbox(\n",
        "            label=\"Initial Text (optional, appended to prompt)\",\n",
        "            placeholder=\"Homer: D'oh!\"\n",
        "        ),\n",
        "        gr.Slider(minimum=100, maximum=3000, value=800, label=\"Max New Tokens (length of script)\", step=50),\n",
        "        gr.Slider(minimum=0.1, maximum=1.5, value=0.9, label=\"Temperature (creativity)\", step=0.05),\n",
        "        gr.Slider(minimum=1, maximum=100, value=50, label=\"Top-K (diversity)\", step=1),\n",
        "        gr.Dropdown(\n",
        "            [\"Homer\", \"Marge\", \"Bart\", \"Lisa\", \"Mr. Burns\", \"Smithers\", \"Chief Wiggum\", \"Moe\", \"Barney\", \"Ned Flanders\", \"Principal Skinner\", \"Apu\", \"Krusty\", \"Grandpa\", \"Milhouse\", \"Nelson\", \"Comic Book Guy\"],\n",
        "            label=\"Character to count dialogues for (optional)\",\n",
        "            value=None, # No default selection\n",
        "            allow_custom_value=True # Allow users to type other character names\n",
        "        ),\n",
        "        gr.Checkbox(label=\"Count dialogues for selected character\", value=False)\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Generated Simpsons Script\", lines=20),\n",
        "    title=\"SimpsonsGPT Story Generator\",\n",
        "    description=\"Generate custom Simpsons stories using a fine-tuned GPT model!\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh7ld6iHt7m0",
        "outputId": "6919f477-dbd4-4b8a-b48a-7a3d389d987f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating your full-length dramatic episode… (this takes 15–30 seconds)\n",
            "\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "SIMPSONS DRAMA: HOMER ACCIDENTALLY CAUSES A MELTDOWN\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "\n",
            "Episode Title: Homer accidentally causes a meltdown\n",
            "\n",
            "Springfield Nuclear Plant  Day\n",
            "\n",
            "FADE IN: D'oh! Not again! (shouting)\n",
            "Professor Frink: You had one job, and somehow, you still outdid yourself. (shouting)\n",
            "Nelson: Why is it always me? (laughing)\n",
            "Grandpa: You call that a plan? I call that chaos. (sarcastically)\n",
            "Troy McClure: That’s not how gravity works, but go on. (confused)\n",
            "Lenny: You can’t prove it was me… okay, maybe you can.\n",
            "Willie: There’s nothing like mild panic to start the day. (muttering)\n",
            "Edna: D'oh! Not again! (excitedly)\n",
            "Maggie: You call that a plan? I call that chaos. (confused)\n",
            "\n",
            "Homer: You can’t prove it was me… okay, maybe you can. (confused)\n",
            "Brandine: You had one job, and somehow, you still outdid yourself. (whispering)\n",
            "Ralph: We’ve officially reached peak nonsense. (sighs)\n",
            "\n",
            "Bart: I could really use a nap right now. (sighs)\n",
            "\n",
            "Chief Wiggum: That’s not how gravity works, but go on. (excitedly)\n",
            "Carl: That’s not a bug, it’s a feature! (excitedly)\n",
            "\n",
            "Mr. Burns: You call that a plan? I call that chaos. (sighs)\n",
            "\n",
            "Chief Wiggum: We’ve officially reached peak nonsense. (laughing)\n",
            "Willie: I can’t believe this happened again. (laughing)\n",
            "Barney: Whoever said laughter is the best medicine never met my cooking. (deadpan)\n",
            "\n",
            "Homer: I could really use a nap right now. (sarcastically)\n",
            "\n",
            "Chief Wiggum: You can’t prove it was me… okay, maybe you can. (muttering)\n",
            "\n",
            "Bart: I could really use a nap right now. (sarcastically)\n",
            "Maude: That’s not a bug, it’s a feature!\n",
            "Agnes Skinner: That’s not a bug, it’s a feature! (shouting)\n",
            "Eddie: D'oh! Not again! (confused)\n",
            "Willie: That’s not how gravity works, but go on. (laughing)\n",
            "Lou: That’s not a bug, it’s a feature! (excitedly)\n",
            "Ralph: There’s no problem that can’t be made worse by my advice. (shouting)\n",
            "Agnes Skinner: Sometimes silence is the only sane response. (sighs)\n",
            "\n",
            "Lisa: That’s not a bug, it’s a feature! (deadpan)\n",
            "Mayor Quimby: Sometimes silence is the only sane response. (muttering)\n",
            "Sideshow Bob: That’s not a bug, it’s a feature! (muttering)\n",
            "Edna: You had one job, and somehow, you still outdid yourself.\n",
            "Lenny: You can’t prove it was me… okay, maybe you can. (confused)\n",
            "Ned: You had one job, and somehow, you still outdid yourself.\n",
            "Maude: There’s nothing like mild panic to start the day. (whispering)\n",
            "Ralph: There’s no problem that can’t be made worse by my advice. (laughing)\n",
            "Sideshow Bob: That’s not how gravity works, but go on. (confused)\n",
            "Lenny: There’s nothing like mild panic to start the day. (sighs)\n",
            "Eddie: Why is it always me? (sighs)\n",
            "\n",
            "Chief Wiggum: I could really use a nap right now. (sighs)\n",
            "Edna: I swear I saw a monkey driving a car yesterday. (shouting)\n",
            "Willie: That’s not how gravity works, but go on. (whispering)\n",
            "Apu: You call that a plan? I call that chaos.\n",
            "Disco Stu: There’s no problem that can’t be made worse by my advice. (whispering)\n",
            "\n",
            "Bart: There’s nothing like mild panic to start the day. (shouting)\n",
            "Krusty: You h\n",
            "\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "END OF EPISODE\n"
          ]
        }
      ],
      "source": [
        "#@title LONG SIMPSONS DRAMA GENERATOR (500–800 lines) — Click play!\n",
        "# Change any of these to direct the drama:\n",
        "starting_scene = \"Springfield Nuclear Plant - Day\" #@param [\"Springfield Nuclear Plant - Day\", \"The Simpsons living room - Night\", \"Springfield Elementary\", \"Moe's Tavern\", \"Krusty the Clown Show set\", \"Springfield Town Hall\", \"The Android's Dungeon comic book store\", \"Kwik-E-Mart\", \"Springfield Retirement Castle\", \"Treehouse of Horror opening\"]\n",
        "main_plot = \"Homer accidentally causes a meltdown\" #@param [\"Homer accidentally causes a meltdown\", \"Lisa discovers corruption in Springfield\", \"Bart becomes mayor for a day\", \"Marge runs for school board\", \"Mr. Burns tries to buy the town\", \"Apu faces deportation\", \"Krusty is cancelled\", \"Grandpa Simpson tells his war stories\", \"A new teacher changes everything\", \"Springfield bans something ridiculous\"]\n",
        "tone = \"Dramatic with heart\" #@param [\"Dramatic with heart\", \"Dark comedy\", \"Pure chaos\", \"Emotional family drama\", \"Political satire\", \"Very silly\", \"Treehouse of Horror (horror)\"]\n",
        "\n",
        "# Build the prompt that forces long, dialogue-heavy output\n",
        "if \"Treehouse of Horror\" in tone:\n",
        "    temperature = 1.0\n",
        "    top_k = 60\n",
        "else:\n",
        "    temperature = 0.9\n",
        "    top_k = 40\n",
        "\n",
        "prompt = f\"\"\"Episode Title: {\"The One Where \" + main_plot.split()[0] + \" \" + \" \".join(main_plot.split()[1:]) if not main_plot.startswith(\"Homer\") else main_plot.capitalize()}\n",
        "\n",
        "{starting_scene}\n",
        "\n",
        "*FADE IN:*\"\"\"\n",
        "\n",
        "model.eval()\n",
        "# Filter out characters from the prompt that are not in the vocabulary\n",
        "filtered_prompt_chars = [c for c in prompt if c in stoi]\n",
        "filtered_prompt = \"\".join(filtered_prompt_chars)\n",
        "context = torch.tensor(encode(filtered_prompt), device=device).unsqueeze(0)\n",
        "\n",
        "print(\"Generating your full-length dramatic episode… (this takes 15–30 seconds)\")\n",
        "\n",
        "full_drama = model.generate(\n",
        "    context,\n",
        "    max_new_tokens=2800,      # ← ~500–800 dialogue lines\n",
        "    temperature=temperature,\n",
        "    top_k=top_k\n",
        ")[0].tolist()\n",
        "\n",
        "script = decode(full_drama)\n",
        "\n",
        "# Clean up a bit for readability\n",
        "script = script.replace(\"Homer:\", \"\\nHomer:\").replace(\"Marge:\", \"\\nMarge:\").replace(\"Bart:\", \"\\nBart:\").replace(\"Lisa:\", \"\\nLisa:\")\n",
        "script = script.replace(\"Mr. Burns:\", \"\\nMr. Burns:\").replace(\"Smithers:\", \"\\nSmithers:\").replace(\"Chief Wiggum:\", \"\\nChief Wiggum:\")\n",
        "\n",
        "print(\"\\n\" + \"═\"*80)\n",
        "print(f\"SIMPSONS DRAMA: {main_plot.upper()}\")\n",
        "print(\"═\"*80 + \"\\n\")\n",
        "print(script)\n",
        "print(\"\\n\" + \"═\"*80)\n",
        "print(\"END OF EPISODE\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}